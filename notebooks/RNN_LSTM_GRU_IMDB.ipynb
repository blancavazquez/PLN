{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blancavazquez/PLN/blob/main/notebooks/RNN_LSTM_GRU_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis de sentimientos\n",
        "\n",
        "El objetivo de esta libreta es estudiar y comparar el rendimiento de las redes recurrentes (RNN, LSTM y GRU) en la tarea de análisis de sentimientos usando la base de datos de IMDB."
      ],
      "metadata": {
        "id": "33PX1bXUWbYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Carga de bibliotecas\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import numpy as np"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:11:53.457018Z",
          "iopub.execute_input": "2024-06-26T14:11:53.457489Z",
          "iopub.status.idle": "2024-06-26T14:11:53.463889Z",
          "shell.execute_reply.started": "2024-06-26T14:11:53.457443Z",
          "shell.execute_reply": "2024-06-26T14:11:53.462719Z"
        },
        "trusted": true,
        "id": "TgAvKFb3WbYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Asignación de recursos disponibles\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:11:53.466232Z",
          "iopub.execute_input": "2024-06-26T14:11:53.466666Z",
          "iopub.status.idle": "2024-06-26T14:11:53.479585Z",
          "shell.execute_reply.started": "2024-06-26T14:11:53.466627Z",
          "shell.execute_reply": "2024-06-26T14:11:53.478342Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EajI4y-7WbYz",
        "outputId": "63d780be-08fd-4faf-dc5d-5b7208948ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de la base de datos IMDB\n",
        "max_features = 500  # Número máximo de palabras para considerar como características 5000\n",
        "max_len = 50  # Las opiniones tendrán este máximo de número de palabras 500\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) #Creación del conjunto de entrenamiento y prueba"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:11:53.480864Z",
          "iopub.execute_input": "2024-06-26T14:11:53.481181Z",
          "iopub.status.idle": "2024-06-26T14:11:59.246723Z",
          "shell.execute_reply.started": "2024-06-26T14:11:53.481142Z",
          "shell.execute_reply": "2024-06-26T14:11:59.245655Z"
        },
        "trusted": true,
        "id": "RlXbOm1eWbY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences: se tendrán una secuencia uniforme\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Creación de tensores de pytorch\n",
        "x_train = torch.tensor(x_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "x_test = torch.tensor(x_test, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:11:59.248540Z",
          "iopub.execute_input": "2024-06-26T14:11:59.248853Z",
          "iopub.status.idle": "2024-06-26T14:12:00.501624Z",
          "shell.execute_reply.started": "2024-06-26T14:11:59.248827Z",
          "shell.execute_reply": "2024-06-26T14:12:00.500405Z"
        },
        "trusted": true,
        "id": "U0sSTZpEWbY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuraciones\n",
        "batch_size = 64\n",
        "train_data = TensorDataset(x_train, y_train)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_data = TensorDataset(x_test, y_test)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:12:00.504359Z",
          "iopub.execute_input": "2024-06-26T14:12:00.504716Z",
          "iopub.status.idle": "2024-06-26T14:12:00.525849Z",
          "shell.execute_reply.started": "2024-06-26T14:12:00.504687Z",
          "shell.execute_reply": "2024-06-26T14:12:00.524894Z"
        },
        "trusted": true,
        "id": "K15FhBT0WbY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------"
      ],
      "metadata": {
        "id": "T4NacsR-ZDR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitectura RNN (Recurrent Neural Network)"
      ],
      "metadata": {
        "id": "sOTlPFaCWbY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = x[:, -1, :]  # Toma la salida del último paso de tiempo\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Hiperparámetros\n",
        "vocab_size = max_features\n",
        "embedding_dim = 128\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "num_layers = 3  # Número de capas de RNN\n",
        "num_epochs = 5\n",
        "\n",
        "# Inicialización del modelo\n",
        "rnn_model = RNNModel(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:12:00.527265Z",
          "iopub.execute_input": "2024-06-26T14:12:00.527681Z",
          "iopub.status.idle": "2024-06-26T14:12:00.552177Z",
          "shell.execute_reply.started": "2024-06-26T14:12:00.527644Z",
          "shell.execute_reply": "2024-06-26T14:12:00.551280Z"
        },
        "trusted": true,
        "id": "uhBQkRH4WbY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Training RNN\"\"\"\n",
        "for epoch in range(num_epochs):\n",
        "    rnn_model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = rnn_model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:12:00.553323Z",
          "iopub.execute_input": "2024-06-26T14:12:00.553650Z",
          "iopub.status.idle": "2024-06-26T14:12:20.317226Z",
          "shell.execute_reply.started": "2024-06-26T14:12:00.553624Z",
          "shell.execute_reply": "2024-06-26T14:12:20.316260Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeAsF4xyWbY2",
        "outputId": "b9e142d6-6b41-49da-a583-f718be066bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.6573\n",
            "Epoch [2/5], Loss: 0.6265\n",
            "Epoch [3/5], Loss: 0.5995\n",
            "Epoch [4/5], Loss: 0.6137\n",
            "Epoch [5/5], Loss: 0.5765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Testing RNN\"\"\"\n",
        "rnn_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = rnn_model(inputs)\n",
        "        predicted = (outputs.squeeze() >= 0.5).float()\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:12:20.318499Z",
          "iopub.execute_input": "2024-06-26T14:12:20.318783Z",
          "iopub.status.idle": "2024-06-26T14:12:21.973725Z",
          "shell.execute_reply.started": "2024-06-26T14:12:20.318759Z",
          "shell.execute_reply": "2024-06-26T14:12:21.972607Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw5O5Y6rWbY3",
        "outputId": "60b8f05c-7ab5-442d-d668-dbce00a44ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------"
      ],
      "metadata": {
        "id": "Bor8hROlZi3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitectura LSTM (Long short - term memory)"
      ],
      "metadata": {
        "id": "T9RXnN5VWbY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = x[:, -1, :]  # Toma la salida del último paso de tiempo\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Hiperparámetros\n",
        "vocab_size = max_features\n",
        "embedding_dim = 128\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "num_layers = 3  # Número de capas de LSTM\n",
        "\n",
        "# Inicialización del modelo\n",
        "lstm_model = LSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:12:21.975229Z",
          "iopub.execute_input": "2024-06-26T14:12:21.975668Z",
          "iopub.status.idle": "2024-06-26T14:12:22.003727Z",
          "shell.execute_reply.started": "2024-06-26T14:12:21.975622Z",
          "shell.execute_reply": "2024-06-26T14:12:22.002624Z"
        },
        "trusted": true,
        "id": "59nhRVyYWbY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Training LSTM\"\"\"\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    lstm_model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = lstm_model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:12:22.004934Z",
          "iopub.execute_input": "2024-06-26T14:12:22.005245Z",
          "iopub.status.idle": "2024-06-26T14:13:56.097606Z",
          "shell.execute_reply.started": "2024-06-26T14:12:22.005217Z",
          "shell.execute_reply": "2024-06-26T14:13:56.096450Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0H_utLFWbY4",
        "outputId": "ebb51fdd-df31-4416-e24d-bac48b59be6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.5836\n",
            "Epoch [2/5], Loss: 0.4769\n",
            "Epoch [3/5], Loss: 0.4404\n",
            "Epoch [4/5], Loss: 0.4024\n",
            "Epoch [5/5], Loss: 0.3631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Testing LSTM\"\"\"\n",
        "lstm_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = lstm_model(inputs)\n",
        "        predicted = (outputs.squeeze() >= 0.5).float()\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:13:56.099373Z",
          "iopub.execute_input": "2024-06-26T14:13:56.099830Z",
          "iopub.status.idle": "2024-06-26T14:14:03.710532Z",
          "shell.execute_reply.started": "2024-06-26T14:13:56.099791Z",
          "shell.execute_reply": "2024-06-26T14:14:03.709258Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1EM4XBoWbY4",
        "outputId": "7d521985-5bae-4c41-ef1c-309e1f6a0cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitectura GRU (Gated Recurrent Unit)"
      ],
      "metadata": {
        "id": "fI8nQ76QWbY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.gru(x)\n",
        "        x = x[:, -1, :]  # Toma la salida del último paso de tiempo\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Hiperparámetros\n",
        "vocab_size = max_features\n",
        "embedding_dim = 128\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "num_layers = 3  # Número de capas de GRU\n",
        "\n",
        "# Inicialización del modelo\n",
        "gru_model = GRUModel(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:14:03.711995Z",
          "iopub.execute_input": "2024-06-26T14:14:03.712328Z",
          "iopub.status.idle": "2024-06-26T14:14:03.738682Z",
          "shell.execute_reply.started": "2024-06-26T14:14:03.712299Z",
          "shell.execute_reply": "2024-06-26T14:14:03.737594Z"
        },
        "trusted": true,
        "id": "TLNO6QXdWbY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Training GRU\"\"\"\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    gru_model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = gru_model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:14:03.743250Z",
          "iopub.execute_input": "2024-06-26T14:14:03.743610Z",
          "iopub.status.idle": "2024-06-26T14:14:46.908050Z",
          "shell.execute_reply.started": "2024-06-26T14:14:03.743575Z",
          "shell.execute_reply": "2024-06-26T14:14:46.906989Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt8YKHHDWbY5",
        "outputId": "d1158cd6-0edb-4ee8-ae7e-a039f148ec23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.5785\n",
            "Epoch [2/5], Loss: 0.4631\n",
            "Epoch [3/5], Loss: 0.4159\n",
            "Epoch [4/5], Loss: 0.3739\n",
            "Epoch [5/5], Loss: 0.3208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Testing GRU\"\"\"\n",
        "gru_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = gru_model(inputs)\n",
        "        predicted = (outputs.squeeze() >= 0.5).float()\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-26T14:14:46.909482Z",
          "iopub.execute_input": "2024-06-26T14:14:46.909815Z",
          "iopub.status.idle": "2024-06-26T14:14:50.318764Z",
          "shell.execute_reply.started": "2024-06-26T14:14:46.909785Z",
          "shell.execute_reply": "2024-06-26T14:14:50.317621Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2E6oV7uWbY5",
        "outputId": "c399e5c1-854f-4c8b-ebb5-7a89bc69701f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7855\n"
          ]
        }
      ]
    }
  ]
}